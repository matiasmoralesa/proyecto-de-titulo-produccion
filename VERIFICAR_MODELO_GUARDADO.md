# ğŸ” Verificar si el Modelo ML se GuardÃ³ Correctamente

## Comandos para Ejecutar en Railway SSH

```bash
# 1. Conectarse a Railway
railway ssh

# 2. Verificar si existe el directorio de modelos
ls -la backend/ml_models/

# 3. Verificar si existe el archivo del modelo
ls -lh backend/ml_models/failure_prediction_model.pkl

# 4. Verificar si existen los encoders
ls -lh backend/ml_models/label_encoders.pkl

# 5. Ver el tamaÃ±o de los archivos (deben ser > 0 bytes)
du -h backend/ml_models/*

# 6. Salir
exit
```

## âœ… QuÃ© Esperar

Si el modelo se guardÃ³ correctamente, deberÃ­as ver:

```
backend/ml_models/
  failure_prediction_model.pkl  (~ 500KB - 2MB)
  label_encoders.pkl            (~ 1KB - 10KB)
```

## ğŸ¯ Si los Archivos Existen

Â¡Perfecto! El modelo estÃ¡ guardado. Ahora puedes:

1. Ir a la aplicaciÃ³n web
2. Ejecutar predicciones
3. DeberÃ­as ver resultados

## âŒ Si los Archivos NO Existen

El error al final del script impidiÃ³ que se guardaran. Necesitas:

1. Corregir el script (ya lo hice)
2. Volver a ejecutar: `python backend/retrain_model.py`

## ğŸ”„ Alternativa: Verificar desde los Logs

TambiÃ©n puedes verificar en los logs de Railway si el modelo se estÃ¡ usando:

```bash
railway logs --tail 50 | grep -i "model\|prediction"
```

Busca mensajes como:
- "Modelo cargado exitosamente"
- "Model loaded"
- "Predictions completed"
